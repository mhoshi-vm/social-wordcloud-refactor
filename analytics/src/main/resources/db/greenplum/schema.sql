CREATE EXTENSION IF NOT EXISTS vector;
CREATE EXTENSION IF NOT EXISTS plpython3u;
CREATE EXTENSION IF NOT EXISTS postgis;
CREATE EXTENSION IF NOT EXISTS madlib;

-- 1. Main Message Table
CREATE TABLE IF NOT EXISTS social_message (
    id               VARCHAR(64),
    origin           VARCHAR(64),
    text             TEXT,
    lang             VARCHAR(2),
    name             TEXT,
    url              TEXT,
    create_date_time TIMESTAMPTZ NOT NULL,
    PRIMARY KEY (id, create_date_time)
)
WITH (
    appendonly = true,
    orientation = column,
    compresstype = zstd,
    compresslevel = 3
)
DISTRIBUTED BY (id)
PARTITION BY RANGE (create_date_time)
(
    DEFAULT PARTITION other
);


-- 2. Sentiment Analysis (Distributed by message_id to co-locate with social_message)
CREATE TABLE IF NOT EXISTS message_entity_sentiment
(
    id               BIGINT GENERATED BY DEFAULT AS IDENTITY,
    message_id       VARCHAR(64),
    msg_timestamp    TIMESTAMPTZ NOT NULL,
    model_name       VARCHAR(255),
    sentiment_label  VARCHAR(255),
    confidence_score REAL,
    PRIMARY KEY (message_id, msg_timestamp)
)
WITH (
    appendonly = true,
    orientation = column,
    compresstype = zstd,
    compresslevel = 3
)
DISTRIBUTED BY (message_id)
PARTITION BY RANGE (msg_timestamp)
(
    DEFAULT PARTITION other
);

-- 3. Text Search Vectors
CREATE TABLE IF NOT EXISTS message_entity_tsvector
(
    message_id  VARCHAR(64),
    msg_timestamp    TIMESTAMPTZ NOT NULL,
    word_vector TSVECTOR,
    PRIMARY KEY (message_id, msg_timestamp)
)
WITH (
    appendonly = true,
    orientation = column,
    compresstype = zstd,
    compresslevel = 3
)
DISTRIBUTED BY (message_id)
PARTITION BY RANGE (msg_timestamp)
(
    DEFAULT PARTITION other
);

-- 4. Analytics Helpers
CREATE OR REPLACE VIEW term_frequency_entity_month  AS
SELECT ROW_NUMBER() OVER (ORDER BY nentry DESC) AS rank,
       word AS term,
       nentry AS count
FROM ts_stat('SELECT word_vector FROM message_entity_tsvector WHERE msg_timestamp >= CURRENT_DATE - INTERVAL ''1 month''')
ORDER BY nentry DESC;

CREATE OR REPLACE VIEW term_frequency_entity_week  AS
SELECT ROW_NUMBER() OVER (ORDER BY nentry DESC) AS rank,
       word AS term,
       nentry AS count
FROM ts_stat('SELECT word_vector FROM message_entity_tsvector WHERE msg_timestamp >= CURRENT_DATE - INTERVAL ''1 week''')
ORDER BY nentry DESC;

CREATE OR REPLACE VIEW term_frequency_entity_day AS
SELECT ROW_NUMBER() OVER (ORDER BY nentry DESC) AS rank,
       word AS term,
       nentry AS count
FROM ts_stat('SELECT word_vector FROM message_entity_tsvector WHERE msg_timestamp >= CURRENT_DATE - INTERVAL ''1 day''')
ORDER BY nentry DESC;

--- 5. Vector Store
CREATE TABLE IF NOT EXISTS vector_store
(
    id         BIGINT GENERATED BY DEFAULT AS IDENTITY,
    message_id VARCHAR(64),
    msg_timestamp    TIMESTAMPTZ NOT NULL,
    metadata   JSONB,
    embedding  VECTOR(1024),
    PRIMARY KEY (message_id, msg_timestamp)
)
WITH (
    appendonly = true,
    orientation = column,
    compresstype = zstd,
    compresslevel = 3
)
DISTRIBUTED BY (message_id)
PARTITION BY RANGE (msg_timestamp)
(
    DEFAULT PARTITION other
);

--- 6. GIS Info
CREATE TABLE IF NOT EXISTS gis_info
(
    id         BIGINT GENERATED BY DEFAULT AS IDENTITY,
    message_id VARCHAR(64),
    msg_timestamp    TIMESTAMPTZ NOT NULL,
    srid       INTEGER DEFAULT 4326,
    gis        TEXT,
    reason     TEXT,
    geom       GEOMETRY(Point, 4326) GENERATED ALWAYS AS (
        ST_GeomFromText(gis, 4326)
        ) STORED,
    point_coords FLOAT8[] GENERATED ALWAYS AS (
        ARRAY[
            ST_X(ST_GeomFromText(gis, 4326)),
            ST_Y(ST_GeomFromText(gis, 4326))
        ]
        ) STORED,
    PRIMARY KEY (message_id, msg_timestamp)
)
WITH (
    appendonly = true,
    orientation = column,
    compresstype = zstd,
    compresslevel = 3
)
DISTRIBUTED BY (message_id)
PARTITION BY RANGE (msg_timestamp)
(
    DEFAULT PARTITION other
);

--- Create function to calculate centroids with madlib
CREATE TABLE IF NOT EXISTS gis_kmeans_result
(
    kmeanspp  madlib.kmeans_result
)DISTRIBUTED REPLICATED;
CREATE OR REPLACE FUNCTION train_and_refresh_clusters() RETURNS TEXT AS '
BEGIN
    DELETE FROM gis_kmeans_result;
    INSERT INTO gis_kmeans_result
    SELECT madlib.kmeanspp(
        ''gis_info'',                  -- Input table
        ''point_coords'',              -- Column with coordinates
        5,                             -- k (Number of clusters)
        ''madlib.squared_dist_norm2'', -- Distance metric
        ''madlib.avg'',                -- Aggregation function
        20,                            -- Max iterations
        0.001                          -- Convergence threshold
    );

    RETURN ''Success: Model retrained and View refreshed.'';
END;
' LANGUAGE plpgsql;

--- Create GIS info table with madlib calculated centroids
CREATE MATERIALIZED VIEW IF NOT EXISTS gis_info_w_centroids with(mv_maintain_mode=full)
AS
WITH defined_centers AS (
    SELECT
        idx AS cluster_id,
        (kmeanspp).centroids[idx][1] AS lon,
        (kmeanspp).centroids[idx][2] AS lat,
        ST_SetSRID(ST_MakePoint((kmeanspp).centroids[idx][1], (kmeanspp).centroids[idx][2]), 4326) AS geom
    FROM
        gis_kmeans_result,
        generate_series(1, array_upper((kmeanspp).centroids, 1)) AS idx
    WHERE (kmeanspp).centroids IS NOT NULL
)
SELECT DISTINCT ON (g.message_id)
    g.message_id,
    g.msg_timestamp,
    g.srid,
    g.geom,
    c.cluster_id,
    ST_Distance(g.geom, c.geom) AS dist_to_center,
    c.geom AS center_geom
FROM
    gis_info g
    CROSS JOIN defined_centers c
WHERE
    g.geom IS NOT NULL
ORDER BY
    g.message_id,
    ST_Distance(g.geom, c.geom) ASC
DISTRIBUTED BY (message_id);

--- 7. Aggregation Layer
-- Greenplum 7 supports mv_maintain_mode=full
CREATE MATERIALIZED VIEW IF NOT EXISTS hourly_message_stats with(mv_maintain_mode=full) AS
SELECT
    date_trunc('hour', create_date_time) AS bucket,
    origin,
    COUNT(*) AS message_count
FROM social_message
GROUP BY bucket, origin
DISTRIBUTED BY (origin);

--- 8. Continuous Aggregate for Stock price
CREATE MATERIALIZED VIEW IF NOT EXISTS daily_stock_metrics with(mv_maintain_mode=full) AS
WITH date_grid AS (
    -- Generate all days between the oldest and newest message
    SELECT
        date_trunc('day', series_date) AS bucket,
        t.ticker
    FROM
        generate_series(
            (SELECT min(create_date_time) FROM social_message WHERE origin = 'stocksprice'),
            (SELECT max(create_date_time) FROM social_message WHERE origin = 'stocksprice'),
            '1 day'::interval
        ) AS series_date
    CROSS JOIN (SELECT DISTINCT (text::jsonb) ->> 'ticker' AS ticker FROM social_message WHERE origin = 'stocksprice') t
),
raw_metrics AS (
    -- Get the actual daily aggregates
    SELECT
        date_trunc('day', create_date_time) AS bucket,
        (text::jsonb) ->> 'ticker' AS ticker,
        AVG(((text::jsonb) ->> 'price')::NUMERIC) AS avg_price,
        SUM(((text::jsonb) ->> 'volume')::BIGINT) AS total_volume
    FROM social_message
    WHERE origin = 'stocksprice'
    GROUP BY 1, 2
)
SELECT
    dg.bucket,
    dg.ticker,
    -- Carry forward the last non-null value for price and volume
    (array_remove(array_agg(rm.avg_price) OVER (PARTITION BY dg.ticker ORDER BY dg.bucket), NULL))[array_upper(array_remove(array_agg(rm.avg_price) OVER (PARTITION BY dg.ticker ORDER BY dg.bucket), NULL), 1)] AS avg_price,
    (array_remove(array_agg(rm.total_volume) OVER (PARTITION BY dg.ticker ORDER BY dg.bucket), NULL))[array_upper(array_remove(array_agg(rm.total_volume) OVER (PARTITION BY dg.ticker ORDER BY dg.bucket), NULL), 1)] AS total_volume
FROM date_grid dg
LEFT JOIN raw_metrics rm ON dg.bucket = rm.bucket AND dg.ticker = rm.ticker
DISTRIBUTED BY (ticker);


--- 9. Create aggregated view to show the full analysis
CREATE OR REPLACE VIEW social_message_analysis AS
SELECT
    s.id AS message_id,
    s.origin,
    s.url,
    sent.sentiment_label,
    gc.cluster_id AS centroid_cluster_id,
    s.create_date_time,
    g.gis
FROM
    social_message s
-- Join with Sentiment Analysis table
LEFT JOIN message_entity_sentiment sent
    ON s.id = sent.message_id
    AND s.create_date_time = sent.msg_timestamp
-- INNER JOIN filters out records if gc (GIS info) does not exist
INNER JOIN gis_info_w_centroids gc
    ON s.id = gc.message_id
    AND s.create_date_time = gc.msg_timestamp
INNER JOIN gis_info g
    ON s.id = g.message_id
    AND s.create_date_time = gc.msg_timestamp
ORDER BY
    s.create_date_time DESC
LIMIT 1000;


--- Cleanup UDF since Greenplum doesn't support FK constraints
-- SELECT delete_social_message_batch(
--     ARRAY['id1', 'id2'],
-- );
CREATE OR REPLACE FUNCTION delete_social_message_batch(
    p_message_ids VARCHAR[]
)
RETURNS VOID AS '
BEGIN
    -- 1. Delete from Sentiment
    DELETE FROM message_entity_sentiment AS t
    USING unnest(p_message_ids) AS input(id)
    WHERE t.message_id = input.id;

    -- 2. Delete from TSVector
    DELETE FROM message_entity_tsvector AS t
    USING unnest(p_message_ids) AS input(id)
    WHERE t.message_id = input.id;

    -- 3. Delete from Vector Store
    DELETE FROM vector_store AS t
    USING unnest(p_message_ids) AS input(id)
    WHERE t.message_id = input.id;

    -- 4. Delete from GIS Info
    DELETE FROM gis_info AS t
    USING unnest(p_message_ids) AS input(id)
    WHERE t.message_id = input.id;

    -- 5. Delete from Parent (Note: column is "id", not "message_id")
    DELETE FROM social_message AS t
    USING unnest(p_message_ids) AS input(id)
    WHERE t.id = input.id;

END;
' LANGUAGE plpgsql;

-- Greenplum does not enforce indexes by default, so not creating thme
-- CREATE INDEX IF NOT EXISTS idx_social_message_origin ON social_message (origin, create_date_time DESC);
-- CREATE INDEX IF NOT EXISTS idx_sentiment_lookup ON message_entity_sentiment (message_id, model_name);
-- CREATE INDEX IF NOT EXISTS idx_tsvector_gin ON message_entity_tsvector USING GIN(word_vector);
-- CREATE INDEX IF NOT EXISTS idx_gis_info_spatial ON gis_info USING GIST (geom);
-- CREATE INDEX IF NOT EXISTS idx_vector_search ON vector_store USING hnsw (embedding vector_cosine_ops);